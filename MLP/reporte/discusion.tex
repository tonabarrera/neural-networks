\section{Discusión de resultados}
Después de realizar cada experimento se pueden sacar varias conclusiones respecto al comportamiento del perceptron multicapa y el porque ocurrió lo que se muestra en las gráficas además de que se puede hacer para mejorar los resultados proporcionados por el perceptron multicapa.

En el primer experimento debido a que se tenían pocos dados la aproximación falla en algunos puntos, aunado al hecho que dicha señal tiene demasiados máximos y mínimos hace que el comportamiento no sea regular, para poder tratar con los máximos y mínimos se pueden agregar más capas o neuronas lo cual aumentaría el numero de parámetros que se deben de ajustar, esto seria suficiente; pero debido a que la cantidad de datos que se tienen son pocos se produciría demasiado ruido, el cual se vería reflejado en una mejor aproximación en la forma general de la gráfica pero al mismo tiempo produciría muchas variaciones a lo largo de toda la función lo cual se conoce como sobreentrenamiento.

El experimento dos tuvo el mejor resultado de todas las pruebas realizadas, en este casi todos los puntos pudieron ser aproximados a excepción de los primeros valores, esto se pudo ser consecuencia de que no se realizo una distribución homogénea optima antes de iniciar el entrenamiento lo cual pudo provocar que no hubiera suficientes datos de entrenamiento al inicio del intervalo; pero a pesar de esto el entrenamiento fue tan bueno que no se necesito tener más iteraciones debido a que el error de aprendizaje fue bastante bajo. Es por esto que una posible mejora que se podría hacer para incrementar la precisión es establecer un error de aprendizaje más bajo para permitir un mayor numero de iteraciones, establecer los valores de pesos, bias y factor de aprendizaje en números que hagan que el entrenamiento sea más rápido.

Por otro lado, el tercer experimento ocurrió algo pelicular debido a que el error de aprendizaje fue bastante bajo lo cual se nota en la gráfica \ref{fig:error3}; pero al mismo tiempo no se aproximo correctamente en los extremos de la función, esto pudo ser causado por no tener suficientes datos en esas secciones de la gráfica o por el hecho de que los cambios fueron tan bruscos que no se hicieron correctamente las aproximaciones, este error no se pudo resolver aumentando el numero de neuronas o capas ya que generaba ruido en la aproximación y provocaba que el aprendizaje terminara por sobreentrenamiento. De tener una mejor selección de bias y de pesos al igual que factor de aprendizaje esto podría mejorar el entrenamiento esta conclusión surge del hecho de que en el experimento dos tanto el error de validación y aprendizaje son bastante bajos pero en este experimento el error de validación es mayor que el de aprendizaje.

Finalmente, el cuarto experimento es el menos satisfactorio de todos, se probaron diversas arquitecturas y configuraciones de estas pero ninguna pudo hacer que se produjera un resultado positivo, los cambios que se generaban en la aproximación y en la evolución del error son mínimos, esto debe de ser causa de que la función a aproximar es demasiado caótica (véase figura \ref{fig:original4}), al inicio de dicha función incluso pareciese que no es una función continua y que solo da saltos entre un valor y otro, sin duda esto merma la eficiencia del perceptrón multicapa.